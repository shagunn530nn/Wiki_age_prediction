{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd3da9d-b6dc-4028-bc6a-50c2976f55ad",
   "metadata": {},
   "source": [
    "# imorting dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782d7d62-d8a4-40ac-8219-e5a7a77b517f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tkinter import filedialog, Label\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from PIL import Image, ImageTk\n",
    "import tensorflow as tf\n",
    "import tkinter as tk\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4afc8d-587f-4a0a-af0f-f0591b2d3ff9",
   "metadata": {},
   "source": [
    "# Load and Extract Data from .mat File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb640875-5772-4663-a198-a3118034e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .mat file\n",
    "data_path = r\"C:\\Users\\Harsh\\Downloads\\data_science01\\dl_projects\\Age_data_work\\data\\wiki_crop\\wiki_crop\\wiki.mat\"\n",
    "data = scipy.io.loadmat(data_path)\n",
    "\n",
    "# Access the 'wiki' structure\n",
    "wiki = data['wiki']\n",
    "\n",
    "# Extracting the fields\n",
    "dob = wiki['dob'][0][0][0]  # Date of birth\n",
    "photo_taken = wiki['photo_taken'][0][0][0]  # Year photo was taken\n",
    "full_path = wiki['full_path'][0][0][0]  # Image paths\n",
    "face_location = wiki['face_location'][0][0][0]  # Face location coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f3d22-ecf2-4ede-a5c0-83601995a074",
   "metadata": {},
   "source": [
    "# Convert DOB to Year and Calculate Ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3a96d-aa0c-49b7-9353-b9fdc2f52f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DOB to the year of birth\n",
    "reference_date = datetime(1, 1, 1)\n",
    "dob_dates = np.array([reference_date + timedelta(days=int(d)) for d in dob])\n",
    "dob_years = np.array([date.year for date in dob_dates])\n",
    "\n",
    "# Calculate ages\n",
    "ages = photo_taken - dob_years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c27d0-9f71-4253-87bf-23ea5badb036",
   "metadata": {},
   "source": [
    "# Verify Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9f2b2-47ce-493d-8556-a03c339f11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of each array\n",
    "print(\"Lengths of the arrays:\")\n",
    "print(\"DOB:\", len(dob))\n",
    "print(\"Photo Taken:\", len(photo_taken))\n",
    "print(\"Full Path:\", len(full_path))\n",
    "print(\"Face Location:\", len(face_location))\n",
    "\n",
    "# Print example values to ensure correctness\n",
    "print(\"\\nExample values:\")\n",
    "print(\"DOB:\", dob[:5])\n",
    "print(\"DOB Dates:\", dob_dates[:5])\n",
    "print(\"DOB Years:\", dob_years[:5])\n",
    "print(\"Photo Taken:\", photo_taken[:5])\n",
    "print(\"Full Path:\", full_path[:5])\n",
    "print(\"Face Location:\", face_location[:5])\n",
    "print(\"Ages:\", ages[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e4d62d-89ff-44a9-887e-7ee095b7351d",
   "metadata": {},
   "source": [
    "# Load Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48378f5-8b6f-4278-8553-fbbebc07d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists for images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Base path to images\n",
    "image_base_path = r\"C:\\Users\\Harsh\\Downloads\\data_science01\\dl_projects\\Age_data_work\\data\\wiki_crop\\wiki_crop\"\n",
    "\n",
    "# Load images and corresponding ages\n",
    "for i, path in enumerate(full_path):\n",
    "    img_path = os.path.join(image_base_path, path[0])\n",
    "    if os.path.exists(img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(ages[i])\n",
    "        else:\n",
    "            print(f\"Image not loaded properly: {img_path}\")\n",
    "    else:\n",
    "        print(f\"Image not found: {img_path}\")\n",
    "\n",
    "print(f\"Loaded {len(images)} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2fb355-17e6-4276-b9ed-e5e1e39f5540",
   "metadata": {},
   "source": [
    "# Splitting Data into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963f324-80f3-4c2d-91bb-0a1eb3f35c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the shapes of the arrays\n",
    "print(f\"X_train shape: {len(X_train)}, y_train shape: {len(y_train)}\")\n",
    "print(f\"X_val shape: {len(X_val)}, y_val shape: {len(y_val)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71426f7-e656-46b9-a7f3-25d3273b4741",
   "metadata": {},
   "source": [
    "# preprocessing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55267a5-0222-4aff-bd3f-c15c031ce1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images_in_batches(image_list, batch_size=1000, target_size=(128, 128)):\n",
    "    processed_images = []\n",
    "    num_images = len(image_list)\n",
    "    \n",
    "    for i in range(0, num_images, batch_size):\n",
    "        batch_images = image_list[i:i+batch_size]\n",
    "        if not batch_images:\n",
    "            continue\n",
    "        processed_batch = []\n",
    "        for img in batch_images:\n",
    "            img_resized = cv2.resize(img, target_size)\n",
    "            img_normalized = img_resized / 255.0  # Normalize to [0, 1] range\n",
    "            processed_batch.append(img_normalized)\n",
    "        processed_images.append(np.array(processed_batch, dtype=np.float32))\n",
    "        print(f\"Processed batch {i // batch_size + 1} / {num_images // batch_size + 1}\")\n",
    "    \n",
    "    return np.concatenate(processed_images, axis=0)\n",
    "\n",
    "# Preprocess the images\n",
    "X_train = preprocess_images_in_batches(X_train)\n",
    "X_val = preprocess_images_in_batches(X_val)\n",
    "\n",
    "# Convert y_train and y_val to numpy arrays\n",
    "y_train = np.array(y_train, dtype=np.int32)\n",
    "y_val = np.array(y_val, dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba49d72-2bb3-432e-937e-49cad2a7b85c",
   "metadata": {},
   "source": [
    "# data augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d58e6-fe9b-4906-9d39-64dbc7973dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2d0345-80d3-4c9c-8b33-6e5a5fa11055",
   "metadata": {},
   "source": [
    "# Defining and compiling cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f39248-d147-45b0-956d-5d705bba7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.4),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ea695-5566-4af3-85c2-a14478fcea30",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc233c-c922-434d-bad5-8bfaebfb3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n",
    "\n",
    "# Train the model with data augmentation\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=64),\n",
    "                    epochs=30, validation_data=(X_val, y_val),\n",
    "                    callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f6aab4-f349-4d64-9b83-bb3a20d61fc4",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d522a-08ae-40b0-9e05-76daa89cef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, mae = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd0d0e3-a4b6-46cf-a8ee-b3c818f0b6f4",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f5343-2ac7-45b9-80bd-0526bd8ff1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(r\"C:\\Users\\Harsh\\Downloads\\data_science01\\dl_projects\\Age_data_work\\Trained cnn model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca3dad5-42dc-49c8-bbdd-92cbbc8b6aa2",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdf94386-6f2e-4006-b9d9-e4b548f653bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harsh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = load_model(r\"C:\\Users\\Harsh\\Downloads\\data_science01\\dl_projects\\Age_data_work\\Trained cnn model\\age_prediction_wiki_model.h5\")\n",
    "\n",
    "# Function to preprocess the image and predict the age\n",
    "def predict_age(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        # Resize the image to 128x128\n",
    "        img_resized = cv2.resize(img, (128, 128))\n",
    "\n",
    "        # Normalize the image to [0, 1]\n",
    "        img_normalized = img_resized / 255.0\n",
    "\n",
    "        # Expand dimensions to match model input\n",
    "        img_expanded = np.expand_dims(img_normalized, axis=0)\n",
    "\n",
    "        # Predict the age\n",
    "        prediction = model.predict(img_expanded)\n",
    "        predicted_age = prediction[0][0]\n",
    "        return predicted_age\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to open a file dialog and choose an image\n",
    "def open_image():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")])\n",
    "    if file_path:\n",
    "        img = Image.open(file_path)\n",
    "        img.thumbnail((250, 250))\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        label_img.config(image=img_tk)\n",
    "        label_img.image = img_tk\n",
    "\n",
    "        # Predict age\n",
    "        age = predict_age(file_path)\n",
    "        if age is not None:\n",
    "            label_result.config(text=f\"Predicted Age: {int(age)}\")\n",
    "        else:\n",
    "            label_result.config(text=\"Error: Could not process the image\")\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Age Prediction\")\n",
    "\n",
    "# Create and place the widgets\n",
    "button_open = tk.Button(root, text=\"Open Image\", command=open_image)\n",
    "button_open.pack()\n",
    "\n",
    "label_img = Label(root)\n",
    "label_img.pack()\n",
    "\n",
    "label_result = Label(root, text=\"Predicted Age: \", font=(\"Helvetica\", 16))\n",
    "label_result.pack()\n",
    "\n",
    "# Run the GUI event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22b7b5-35ae-44b3-991b-9d441d2708eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
